<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="robots" content="index,follow">
    <meta name="author" content="Sergio Martino"><link type="application/atom+xml" rel="alternate" href="https://blog.sergiomartino.com/feed.xml" title="Dailygrind" /><!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Scraping news with Python | Dailygrind</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Scraping news with Python" />
<meta name="author" content="Sergio Martino" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A quick tutorial that explains how to use Python&#39;s BeautifulSoup library to scrape BBC News articles." />
<meta property="og:description" content="A quick tutorial that explains how to use Python&#39;s BeautifulSoup library to scrape BBC News articles." />
<link rel="canonical" href="https://blog.sergiomartino.com/2020/06/scraping-news-with-python/" />
<meta property="og:url" content="https://blog.sergiomartino.com/2020/06/scraping-news-with-python/" />
<meta property="og:site_name" content="Dailygrind" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-06-16T00:00:00-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Scraping news with Python" />
<script type="application/ld+json">
{"url":"https://blog.sergiomartino.com/2020/06/scraping-news-with-python/","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.sergiomartino.com/2020/06/scraping-news-with-python/"},"author":{"@type":"Person","name":"Sergio Martino"},"headline":"Scraping news with Python","dateModified":"2020-06-16T00:00:00-05:00","datePublished":"2020-06-16T00:00:00-05:00","description":"A quick tutorial that explains how to use Python&#39;s BeautifulSoup library to scrape BBC News articles.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<meta property="og:image" content="https://blog.sergiomartino.com/assets/me.jpg" />
    <link rel="icon" type="image/png" href="/assets/favicon.png">
    <link rel="dns-prefetch" href="//fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>
    
    <style>.highlight{background:#ffffff}.highlight .c{color:#999988;font-style:italic}.highlight .err{color:#a61717;background-color:#e3d2d2}.highlight .k{color:#0e335e;font-weight:bold}.highlight .o{font-weight:bold}.highlight .cm{color:#999988;font-style:italic}.highlight .cp{color:#999999;font-weight:bold}.highlight .c1{color:#999988;font-style:italic}.highlight .cs{color:#999999;font-weight:bold;font-style:italic}.highlight .gd{color:#000000;background-color:#ffdddd}.highlight .gd .x{color:#000000;background-color:#ffaaaa}.highlight .ge{font-style:italic}.highlight .gr{color:#aa0000}.highlight .gh{color:#999999}.highlight .gi{color:#000000;background-color:#ddffdd}.highlight .gi .x{color:#000000;background-color:#aaffaa}.highlight .go{color:#888888}.highlight .gp{color:#555555}.highlight .gs{font-weight:bold}.highlight .gu{color:#aaaaaa}.highlight .gt{color:#aa0000}.highlight .kc{font-weight:bold}.highlight .kd{color:#0e335e;font-weight:bold}.highlight .kp{font-weight:bold}.highlight .kr{font-weight:bold}.highlight .kt{color:#445588;font-weight:bold}.highlight .m{color:#009999}.highlight .s{color:#d14}.highlight .na{color:#008080}.highlight .nb{color:#0086B3}.highlight .nc{color:#445588;font-weight:bold}.highlight .no{color:#008080}.highlight .ni{color:#800080}.highlight .ne{color:#990000;font-weight:bold}.highlight .nf{color:#990000;font-weight:bold}.highlight .nn{color:#555555}.highlight .nt{color:#000080}.highlight .nv{color:#008080}.highlight .ow{font-weight:bold}.highlight .w{color:#bbbbbb}.highlight .mf{color:#009999}.highlight .mh{color:#009999}.highlight .mi{color:#009999}.highlight .mo{color:#009999}.highlight .sb{color:#d14}.highlight .sc{color:#d14}.highlight .sd{color:#d14}.highlight .s2{color:#d14}.highlight .se{color:#d14}.highlight .sh{color:#d14}.highlight .si{color:#d14}.highlight .sx{color:#d14}.highlight .sr{color:#009926}.highlight .s1{color:#d14}.highlight .ss{color:#990073}.highlight .bp{color:#999999}.highlight .vc{color:#008080}.highlight .vg{color:#008080}.highlight .vi{color:#008080}.highlight .il{color:#009999}*{margin:0;padding:0;border:0;font-weight:normal}:root{--main-size: 65%;--blog-size: 900px;--content-spacing: 1.55rem;--text-font: "Lusitana", serif;--text-code-font: Consolas, monaco, monospace;--color-text: #333;--color-text-lighter: #a0a0a0;--color-background: #fdfdfd;--color-background-lighter: #ffffff;--color-background-opposite: #000000;--color-shadow: rgba(0, 0, 0, 0.3);--color-foreground: #cccccc;--color-foreground-lighter: #f4f3f3;--color-code-emphasised: #3792c8}body{background:var(--color-background);font-family:var(--text-font)}a{text-decoration:none;border-bottom:1px solid var(--color-text);color:var(--color-text)}.upload{position:fixed;top:50px;right:0}.blog{width:var(--blog-size);margin:60px auto 0 auto}aside{position:fixed}main{width:var(--main-size);float:right}aside *{list-style-type:none}aside .me{margin-top:1rem}aside .me h1{font-size:1.3rem;margin-bottom:0.3rem}aside .me p{font-size:0.9rem}aside nav{margin-top:2rem}aside nav li{margin-bottom:0.7rem}aside footer{margin-top:3rem;font-size:0.7rem}aside footer,aside footer a{color:var(--color-text-lighter);border-color:var(--color-text-lighter)}aside footer a{border-style:dotted}aside footer p{margin-bottom:5px}.logo img{width:100px;border-radius:50%;box-shadow:1px 1px 1px var(--color-shadow);border:2px solid var(--color-background-lighter)}.logo img:hover{filter:brightness(1.1)}.logo a{border:0}.hero{margin-top:2rem;text-align:center}.hero figcaption{font-size:0.7rem;margin-top:1rem}.hero img{max-height:200px;max-width:400px}.article h1,.page h1{font-size:2.3rem}.article h2{font-size:0.7rem;font-variant:small-caps;margin-top:0.5rem}.article h2 a{font-variant:none}.article__content{margin-top:2rem}.article__content h3,.article__content ul,.article__content ol,.article__content p,.article__content blockquote,.article__content pre,.page p,.page ul,.page ol{margin-bottom:var(--content-spacing)}.article__content ul,.article__content ol,.page ul,.page ol{margin-top:-0.5rem}.article__content h3{font-size:1.5rem;margin-top:4rem}.article__content ul,.article__content ol,.page ul,.page ol{margin-left:2rem}.article__content p,.article__content li,.page p,.page li{line-height:1.7rem;font-size:1.1rem}.page li,.article__content li{margin-bottom:0.2rem}.article__content blockquote{border-left:5px solid var(--color-foreground);padding:1.5rem;background:var(--color-foreground-lighter)}.article__content blockquote p{margin:0}.article__content code{background:var(--color-foreground-lighter);line-height:1.2rem}.article__content strong{font-family:var(--text-code-font);color:var(--color-code-emphasised);background:var(--color-foreground-lighter);padding:2px 6px;font-size:0.8rem}.article__content img{width:100%}.page h1{margin-bottom:50px}.page strong{font-weight:bold}hr{background:linear-gradient(to right, var(--color-background-lighter), var(--color-foreground), var(--color-background-lighter));height:1px;margin:3rem 0}.paginate-links{margin-bottom:2rem;text-align:center;display:flex;justify-content:space-between}.contacts{list-style-type:none;overflow:hidden;margin-left:0 !important}.contacts li{float:left;margin-right:1rem}.highlight pre{background:var(--color-foreground-lighter);padding:1rem;overflow:auto}.highlight code{font-size:0.75rem;font-family:var(--text-code-font)}.linked-list{margin-top:0 !important}.linked-list li{margin-bottom:0.5rem}.page-about-me ul{list-style-type:none;overflow:hidden;margin-left:0}.page-about-me ul li{float:left;margin-right:1rem}.page-archive h3{margin-bottom:0.6rem;font-size:1.4rem}.page-archive .archive-list{list-style-type:none}.page-archive .archive-list.yearly{position:relative;margin-bottom:3rem;margin-top:2rem;padding-left:100px;margin-left:0 !important}.page-archive>.archive-list span{position:absolute;left:0}@media screen and (max-width: 1200px){html{font-size:15px}.blog{width:100%}aside{position:static;text-align:center}main{float:none;width:85%;margin:3rem auto}h1,h2{text-align:center}.page h1,.article h1{font-size:1.7rem}.page h1{margin-bottom:25px}.page-archive h3{text-align:center}.page-archive .yearly,.page-archive .monthly{padding-left:0 !important;margin-left:0 !important}.page-archive .yearly li span{position:static;display:block;text-align:center;margin:1rem 0}.page-archive .monthly li{text-align:center;line-height:1.5rem;margin-bottom:0.75rem}.article__content pre{font-size:11px}}
</style>
    <link href="https://fonts.googleapis.com/css2?family=Lusitana:wght@400;700&display=swap" rel="stylesheet"> 
</head>

  <body>
    <div class="blog">
        <aside>
            <div class="logo">
                <a href="/" title="Yup, that's me"><img src="/assets/me.jpg"></a>
            </div>
            <div class="me">
                <h1>Dailygrind</h1>
                <p>Writing code with a pencil.</p>
            </div>
            <nav>
                <ul>
                    <li><a href="/about-me">About me</a></li>
                    <li><a href="/about-this-blog">About this blog</a></li>
                    <li><a href="/archive">Archive</a></li>
                    <li><a href="/feed.xml">Rss</a></li>
                </ul>
            </nav>
            <footer>
                © 2021<br>
                Author: Sergio Martino<br>
                Engine: <a href="https://jekyllrb.com/" target="_blank" rel="noopener">Jekyll 4.1.1</a>
            </footer>
        </aside>
        <main>
            <section>
    

<article class="article">
    <h1>Scraping news with Python</h1>
    <h2>June 2020 | <a href="/2020/06/scraping-news-with-python/">Permalink</a></h2>
    <figure class="hero">
        <img src="/post-assets/illustrations/2020/scraping-news-with-python.svg">
        <figcaption>Illustration by <a href="https://www.instagram.com/barbara_rodeghiero" target="_blank" rel="noopener">Barbara</a></figcaption>
    </figure>

    <div class="article__content">
        <p>In this article, I will explore how you can scrape a newspaper website and extract articles using <strong>python</strong> and the command line. 
In general, I would recommend python for everything that involves CLI for its excellent tooling.</p>

<p>Let’s have a look at how this can be achieved using <strong>click</strong> (to install
it you can <strong>pip install click</strong>), a python library that streamlines your work on the CLI:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">click</span>
<span class="kn">import</span> <span class="nn">importlib</span>

<span class="o">@</span><span class="n">click</span><span class="p">.</span><span class="n">command</span><span class="p">()</span>
<span class="o">@</span><span class="n">click</span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">"--scraper"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="n">scraper</span><span class="p">):</span>
    <span class="k">pass</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</code></pre></div></div>

<p>Since every website is built differently in terms of html elements, we would want to separate our scrapers into different classes and provide a dedicated extraction logic.
A simple <a href="https://en.wikipedia.org/wiki/Strategy_pattern">strategy pattern</a> will allow us to pick the correct scraper according to the command line argument:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">get_scraper</span><span class="p">(</span><span class="n">scraper</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">name</span> <span class="o">=</span> <span class="n">scraper</span> <span class="o">+</span> <span class="s">"Scraper"</span> <span class="c1"># NewsPaperScraper class
</span>        <span class="n">module</span> <span class="o">=</span> <span class="n">import_module</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">name</span><span class="p">)()</span>
    <span class="k">except</span> <span class="nb">ModuleNotFoundError</span> <span class="k">as</span> <span class="n">error</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>
</code></pre></div></div>

<p>Now that we have our scraper class and an available instance of it, we need a way to reach the news website and read its content. A simple <em>get</em> request in python can be carried out using <strong>requests</strong> (to install it you can <strong>pip install requests</strong>):</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">requests</span>
<span class="n">page</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"http://www.newspaper.com"</span><span class="p">)</span>
<span class="n">page</span><span class="p">.</span><span class="n">text</span> <span class="c1"># your news in html
</span></code></pre></div></div>

<p>To extract articles from a piece of html we need an html tree traverser. Thankfully, there’s a nice library called <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/">BeautifulSoup</a> that does just that (among other things). Let’s install it with <strong>pip install beautifulsoup4</strong>. Before using our scraped html with BeatifulSoup, we also need to make sure it’s encoded correctly:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">get_parser</span><span class="p">(</span><span class="n">registered_scraper</span><span class="p">,</span> <span class="n">html</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">html</span> <span class="o">=</span> <span class="nb">bytes</span><span class="p">(</span><span class="n">html</span><span class="p">,</span> <span class="n">registered_scraper</span><span class="p">.</span><span class="n">encoding</span><span class="p">)</span>
    <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">error</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>
        <span class="n">html</span> <span class="o">=</span> <span class="s">""</span>

<span class="k">return</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">html</span><span class="p">,</span> <span class="s">"html.parser"</span><span class="p">)</span>
</code></pre></div></div>

<p>Finally, let’s implement our news scraper:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">NewsPaperScraper</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="n">location</span> <span class="o">=</span> <span class="s">"https://www.newspaper.com"</span>
    <span class="n">encoding</span> <span class="o">=</span> <span class="s">"utf-8"</span>

    <span class="k">def</span> <span class="nf">extract_articles</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parser</span><span class="p">):</span>
        <span class="c1"># simplified, you might need to lookup specific DOM elements
</span>        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">extract_article</span><span class="p">,</span> <span class="n">parser</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">".news-article"</span><span class="p">)))</span>
    
    <span class="k">def</span> <span class="nf">extract_article</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">article_block</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">article_block</span><span class="p">.</span><span class="n">getText</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="wrapping-it-all-up">Wrapping it all up</h3>

<p>You can have a look at a working example for <a href="https://www.bbc.co.uk/news">BBC News</a> on my <a href="https://github.com/sergiomartino/python-news-scraper">github repo</a>. Just clone the repo and install from <strong>requirements.txt</strong> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install</span> <span class="nt">-r</span> requirements.txt
python scrape.py <span class="nt">--scraper</span><span class="o">=</span>BBCNews
</code></pre></div></div>

        <hr />
    </div>
</article>
</section>
        </main>
    </div>
  </body>
</html>
